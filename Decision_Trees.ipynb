{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Decision_Trees.ipynb",
      "provenance": [],
      "private_outputs": true,
      "authorship_tag": "ABX9TyMvmw6+enmckhR/J9gbocCv",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/stephenfrein/tree_models/blob/master/Decision_Trees.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R1pGfpFyMi7p",
        "colab_type": "text"
      },
      "source": [
        "# Get and Examine Our Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "88uYK1hQ4oiy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# modules we will need\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "from sklearn import metrics\n",
        "from sklearn import tree\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.tree.export import export_text\n",
        "\n",
        "# get raw data and put in data frame\n",
        "url = \"https://drive.google.com/uc?export=download&id=1Okb4RuShkQ0-dxMj0xeBWnrmq1uIsuOw\"\n",
        "cars_raw = pd.read_csv(url)\n",
        "cars_raw.head(n=10)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SL89LfEWLtNA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# examine data\n",
        "cars_raw.describe(include='all')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PYz7ISZZMHCl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# base rates of acceptable / unacceptable\n",
        "cars_raw['acceptability'].value_counts(normalize=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3wNInK7PMrT1",
        "colab_type": "text"
      },
      "source": [
        "# Training/Test Split and Building the Tree\n",
        "\n",
        "![Training and Test Split](https://data-flair.training/blogs/wp-content/uploads/sites/2/2018/08/1-16.png)\n",
        "\n",
        "We will break our data into training and test sets.\n",
        "\n",
        "Training set is used to build model – what X values explain our Y?\n",
        "\n",
        "Test set allows us to check our model against data it has never “seen” and allows us to estimate its performance against future data\n",
        "\n",
        "Other methods involve use of cross-validation and validation sets so we can tune models without compromising independence of test data (but we won’t go there right now).\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aIVLs_cPQTqc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# create a separate copy - usually need to massage the data\n",
        "cars_clean = cars_raw.copy()\n",
        "\n",
        "# predictor variables - all but column called acceptability\n",
        "X = cars_clean.drop(\"acceptability\",1)\n",
        "# target variable\n",
        "y = cars_clean[\"acceptability\"]\n",
        "\n",
        "# split into training (70%) and test (30%) sets with seed value for reproducibiity\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=123)\n",
        "\n",
        "# decision tree classifier with max depth to avoid overfitting\n",
        "simple_tree = DecisionTreeClassifier(max_depth=3, criterion='gini')\n",
        "# train decision tree classifer\n",
        "simple_tree = simple_tree.fit(X_train,y_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vyrrnlSfRUpa",
        "colab_type": "text"
      },
      "source": [
        "# Oh no! What happened?\n",
        "\n",
        "Implementation of decision trees in scikit-learn can’t handle character values – need to “one-hot” encode these!\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HwKacgqGT24T",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# see current data types\n",
        "X.dtypes"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WxUMJPsJTuyP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "### TRY AGAIN ###\n",
        "\n",
        "# create a separate copy - usually need to massage the data\n",
        "cars_clean = cars_raw.copy()\n",
        "\n",
        "### CLEAN DATA THIS TIME ###\n",
        "# one-hot encode character variables\n",
        "cars_clean = pd.get_dummies(cars_clean,columns=[\"purchase_cost\",\"maint_cost\",\"trunk_size\",\"safety_rating\"])\n",
        "\n",
        "# predictor variables - all but column called acceptability\n",
        "X = cars_clean.drop(\"acceptability\",1)\n",
        "# target variable\n",
        "y = cars_clean[\"acceptability\"]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dN_5lj2oV_Nf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# what does data frame look like?\n",
        "X.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "KI1pL1ZVVUft",
        "colab": {}
      },
      "source": [
        "# see data types now\n",
        "X.dtypes"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j5h7hGUrVRTa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# okay, let's try to build our tree again\n",
        "\n",
        "# split into training (70%) and test (30%) sets with seed value for reproducibiity\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=123)\n",
        "\n",
        "# decision tree classifier with max depth to avoid overfitting\n",
        "simple_tree = DecisionTreeClassifier(max_depth=3, criterion='gini')\n",
        "# train decision tree classifer\n",
        "simple_tree = simple_tree.fit(X_train,y_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_RIl0tmkY7rk",
        "colab_type": "text"
      },
      "source": [
        "Implementation of decision trees in scikit-learn does not like null (NaN) values – we need to get rid of them!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bP0-TxBmYaZ5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# where are those pesky nulls?\n",
        "X.isna().sum()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lRUnoZ52ZwDS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# one more time\n",
        "\n",
        "# create a separate copy - usually need to massage the data\n",
        "cars_clean = cars_raw.copy()\n",
        "\n",
        "# one-hot encode character variables\n",
        "cars_clean = pd.get_dummies(cars_clean,columns=[\"purchase_cost\",\"maint_cost\",\"trunk_size\",\"safety_rating\"])\n",
        "### NEW CLEANING STEP ###\n",
        "# drop na (null values)\n",
        "cars_clean = cars_clean.dropna()\n",
        "\n",
        "# predictor variables - all but column called acceptability\n",
        "X = cars_clean.drop(\"acceptability\",1)\n",
        "# target variable\n",
        "y = cars_clean[\"acceptability\"]\n",
        "\n",
        "X.isna().sum()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "BdsyPPOvaupP",
        "colab": {}
      },
      "source": [
        "# try to build our tree one last time\n",
        "\n",
        "# split into training (70%) and test (30%) sets with seed value for reproducibiity\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=123)\n",
        "\n",
        "# decision tree classifier with max depth to avoid overfitting\n",
        "simple_tree = DecisionTreeClassifier(max_depth=3, criterion='gini')\n",
        "# train decision tree classifer\n",
        "simple_tree = simple_tree.fit(X_train,y_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mMFgrx9Aa-VR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# plot it\n",
        "plt.figure(figsize=(2,2), dpi=600)\n",
        "tree.plot_tree(simple_tree.fit(X_train,y_train), feature_names = list(X.columns), \n",
        "               class_names=['acceptable','unacceptable'], filled=True)\n",
        "print(export_text(simple_tree, feature_names = list(X.columns)))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6vb9PD7Jf8ga",
        "colab_type": "text"
      },
      "source": [
        "# Model Peformance and Predictions\n",
        " "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e22XJFxMgP5t",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# predict the response for test dataset\n",
        "y_pred = simple_tree.predict(X_test)\n",
        "# how many were classified correctly\n",
        "print(\"Simple Tree Accuracy:\", metrics.accuracy_score(y_test, y_pred))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "injvpKySiWpo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# a concept like precision reguires that we specify a target class with pos_label\n",
        "# precision - when we said a car would be acceptable, how often were we right\n",
        "print(\"Precision:\",metrics.precision_score(y_test, y_pred, pos_label=\"acc\"))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TTWENGE_jWUU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# recall - what % of the ultimately acceptable cars did we find\n",
        "print(\"Recall:\",metrics.recall_score(y_test, y_pred, pos_label=\"acc\"))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C04HF4-rj--b",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# F1  is harmonic mean of precision and recall - an \"average\" that is weighted toward the lower number\n",
        "print(\"F1 Score:\",metrics.f1_score(y_test, y_pred, pos_label=\"acc\"))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "47lLSKLjgjZT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# set up new car examples for predictions\n",
        "# p = persons, m = maintenance very high, s = safety rating low\n",
        "#              p               m         s\n",
        "new_car1 = [[2,2,0,0,0,1,0,0,0,1,1,0,1,0,0,0]]\n",
        "\n",
        "pred_for_new_car1 = simple_tree.predict(new_car1)\n",
        "print('Car 1 acceptability prediction: ' + str(pred_for_new_car1[0]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hq7mJuBzhUE6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# p = persons, m = maintenance very high, s = safety rating low\n",
        "#              p               m         s\n",
        "new_car2 = [[2,4,0,0,0,1,0,0,0,0,1,0,1,0,0,0]]\n",
        "\n",
        "pred_for_new_car2 = simple_tree.predict(new_car2)\n",
        "print('Car 2 acceptability prediction: ' + str(pred_for_new_car2[0]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JTyCiPickkFD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# create a new third car and make a prediction\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SaEfDl68X0Jh",
        "colab_type": "text"
      },
      "source": [
        "# Highly Dependent on Sample\n",
        "\n",
        "Single decision trees are highly dependent on the sample data used. Go back and change your seed value for the train/test split and see if your tree changes.\n",
        "\n",
        "This suggests that they may not be robust enough for many uses."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x-pN3ByRoiO3",
        "colab_type": "text"
      },
      "source": [
        "# Exercise #1\n",
        "\n",
        "You have been asked to predict whether or not a movie is likely to receive a high score on IMDB. \n",
        "\n",
        "You will be working with a file of IMDB data that you download from [https://drive.google.com/uc?export=download&id=1WvXg871_CZe51bWnIkuAIMoMzAmG9ke_] (last underscore is part of the URL). You will be building a model to predicting the values in the *imdb_score_high* column. A “1” designates a high-scoring movie and a “0” designates a movie that does not have a high score.\n",
        "\n",
        "Build a decision tree model on a training set taken from the data and evaluate the performance of your model against the test set. Determine your metrics for accuracy, precision, recall, and F1 score.\n",
        "\n",
        "Finally, tell us whether the following movie would have earned a high score or not.\n",
        "\n",
        "```\n",
        "num_critic_for_reviews\t86\n",
        "duration\t130\n",
        "director_facebook_likes\t39\n",
        "lead_actor_facebook_likes\t2000\n",
        "gross\t9589875\n",
        "num_voted_users\t16673\n",
        "cast_total_facebook_likes\t5162\n",
        "studio\tCosmic\n",
        "facenumber_in_poster\t0\n",
        "num_user_for_reviews\t45\n",
        "budget\t41000000\n",
        "title_year\t2008\n",
        "aspect_ratio\t2.35\n",
        "movie_facebook_likes\t0\n",
        "```\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TnDLVOhVYih8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# enjoy!"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}